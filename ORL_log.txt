train logï¼š

train: 
(16601, 112, 92)
test: 
(4146, 112, 92)
13280 train samples
3321 valid samples
4146 test samples
Train on 13280 samples, validate on 3321 samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_21 (Conv2D)           (None, 112, 92, 32)       320       
_________________________________________________________________
activation_31 (Activation)   (None, 112, 92, 32)       0         
_________________________________________________________________
conv2d_22 (Conv2D)           (None, 110, 90, 32)       9248      
_________________________________________________________________
activation_32 (Activation)   (None, 110, 90, 32)       0         
_________________________________________________________________
max_pooling2d_11 (MaxPooling (None, 55, 45, 32)        0         
_________________________________________________________________
dropout_16 (Dropout)         (None, 55, 45, 32)        0         
_________________________________________________________________
conv2d_23 (Conv2D)           (None, 55, 45, 64)        18496     
_________________________________________________________________
activation_33 (Activation)   (None, 55, 45, 64)        0         
_________________________________________________________________
conv2d_24 (Conv2D)           (None, 53, 43, 64)        36928     
_________________________________________________________________
activation_34 (Activation)   (None, 53, 43, 64)        0         
_________________________________________________________________
max_pooling2d_12 (MaxPooling (None, 26, 21, 64)        0         
_________________________________________________________________
dropout_17 (Dropout)         (None, 26, 21, 64)        0         
_________________________________________________________________
flatten_6 (Flatten)          (None, 34944)             0         
_________________________________________________________________
dense_11 (Dense)             (None, 512)               17891840  
_________________________________________________________________
activation_35 (Activation)   (None, 512)               0         
_________________________________________________________________
dropout_18 (Dropout)         (None, 512)               0         
_________________________________________________________________
dense_12 (Dense)             (None, 40)                20520     
_________________________________________________________________
activation_36 (Activation)   (None, 40)                0         
=================================================================
Total params: 17,977,352
Trainable params: 17,977,352
Non-trainable params: 0
_________________________________________________________________
Epoch 1/40
13280/13280 [==============================] - 101s - loss: 2.6623 - acc: 0.2712 - val_loss: 0.7670 - val_acc: 0.8254
Epoch 2/40
13280/13280 [==============================] - 99s - loss: 0.6146 - acc: 0.8000 - val_loss: 0.1111 - val_acc: 0.9792
Epoch 3/40
13280/13280 [==============================] - 98s - loss: 0.2491 - acc: 0.9189 - val_loss: 0.0551 - val_acc: 0.9874
Epoch 4/40
13280/13280 [==============================] - 97s - loss: 0.1344 - acc: 0.9553 - val_loss: 0.0426 - val_acc: 0.9868
Epoch 5/40
13280/13280 [==============================] - 98s - loss: 0.0970 - acc: 0.9698 - val_loss: 0.0167 - val_acc: 0.9949
Epoch 6/40
13280/13280 [==============================] - 98s - loss: 0.0735 - acc: 0.9771 - val_loss: 0.0128 - val_acc: 0.9976
Epoch 7/40
13280/13280 [==============================] - 98s - loss: 0.0505 - acc: 0.9819 - val_loss: 0.0097 - val_acc: 0.9967
Epoch 8/40
13280/13280 [==============================] - 98s - loss: 0.0549 - acc: 0.9828 - val_loss: 0.0050 - val_acc: 0.9988
Epoch 9/40
13280/13280 [==============================] - 98s - loss: 0.0378 - acc: 0.9867 - val_loss: 0.0117 - val_acc: 0.9964
Epoch 10/40
13280/13280 [==============================] - 98s - loss: 0.0331 - acc: 0.9894 - val_loss: 0.0072 - val_acc: 0.9982
Epoch 11/40
13280/13280 [==============================] - 98s - loss: 0.0250 - acc: 0.9916 - val_loss: 0.0054 - val_acc: 0.9988
Epoch 12/40
13280/13280 [==============================] - 98s - loss: 0.0268 - acc: 0.9909 - val_loss: 0.0302 - val_acc: 0.9901
Epoch 13/40
13280/13280 [==============================] - 97s - loss: 0.0254 - acc: 0.9917 - val_loss: 0.0054 - val_acc: 0.9988
Epoch 14/40
13280/13280 [==============================] - 96s - loss: 0.0246 - acc: 0.9925 - val_loss: 0.0041 - val_acc: 0.9991
Epoch 15/40
13280/13280 [==============================] - 96s - loss: 0.0140 - acc: 0.9959 - val_loss: 0.0010 - val_acc: 0.9994
Epoch 16/40
13280/13280 [==============================] - 96s - loss: 0.0103 - acc: 0.9963 - val_loss: 0.0044 - val_acc: 0.9985
Epoch 17/40
13280/13280 [==============================] - 97s - loss: 0.0158 - acc: 0.9950 - val_loss: 0.0023 - val_acc: 0.9994
Epoch 18/40
13280/13280 [==============================] - 98s - loss: 0.0136 - acc: 0.9949 - val_loss: 0.0033 - val_acc: 0.9994
Epoch 19/40
13280/13280 [==============================] - 98s - loss: 0.0141 - acc: 0.9950 - val_loss: 0.0018 - val_acc: 0.9994
Epoch 20/40
13280/13280 [==============================] - 98s - loss: 0.0132 - acc: 0.9958 - val_loss: 0.0021 - val_acc: 0.9994
Epoch 21/40
13280/13280 [==============================] - 98s - loss: 0.0114 - acc: 0.9965 - val_loss: 0.0030 - val_acc: 0.9991
Epoch 22/40
13280/13280 [==============================] - 98s - loss: 0.0129 - acc: 0.9962 - val_loss: 0.0033 - val_acc: 0.9988
Epoch 23/40
13280/13280 [==============================] - 98s - loss: 0.0114 - acc: 0.9962 - val_loss: 0.0041 - val_acc: 0.9991
Epoch 24/40
13280/13280 [==============================] - 98s - loss: 0.0102 - acc: 0.9965 - val_loss: 0.0050 - val_acc: 0.9979
Epoch 25/40
13280/13280 [==============================] - 98s - loss: 0.0126 - acc: 0.9963 - val_loss: 0.0025 - val_acc: 0.9991
Epoch 26/40
13280/13280 [==============================] - 98s - loss: 0.0092 - acc: 0.9968 - val_loss: 3.9161e-04 - val_acc: 1.0000
Epoch 27/40
13280/13280 [==============================] - 98s - loss: 0.0107 - acc: 0.9967 - val_loss: 0.0020 - val_acc: 0.9991
Epoch 28/40
13280/13280 [==============================] - 98s - loss: 0.0156 - acc: 0.9947 - val_loss: 0.0014 - val_acc: 0.9997
Epoch 29/40
13280/13280 [==============================] - 98s - loss: 0.0086 - acc: 0.9971 - val_loss: 0.0017 - val_acc: 0.9991
Epoch 30/40
13280/13280 [==============================] - 98s - loss: 0.0039 - acc: 0.9988 - val_loss: 0.0037 - val_acc: 0.9991
Epoch 31/40
13280/13280 [==============================] - 98s - loss: 0.0076 - acc: 0.9974 - val_loss: 4.0399e-04 - val_acc: 1.0000
Epoch 32/40
13280/13280 [==============================] - 98s - loss: 0.0101 - acc: 0.9971 - val_loss: 0.0014 - val_acc: 0.9997
Epoch 33/40
13280/13280 [==============================] - 98s - loss: 0.0115 - acc: 0.9969 - val_loss: 0.0013 - val_acc: 0.9994
Epoch 34/40
13280/13280 [==============================] - 98s - loss: 0.0070 - acc: 0.9980 - val_loss: 7.2430e-04 - val_acc: 0.9997
Epoch 35/40
13280/13280 [==============================] - 98s - loss: 0.0092 - acc: 0.9974 - val_loss: 0.0024 - val_acc: 0.9997
Epoch 36/40
13280/13280 [==============================] - 98s - loss: 0.0125 - acc: 0.9960 - val_loss: 7.4822e-04 - val_acc: 0.9997
Epoch 37/40
13280/13280 [==============================] - 98s - loss: 0.0093 - acc: 0.9970 - val_loss: 0.0015 - val_acc: 0.9991
Epoch 38/40
13280/13280 [==============================] - 98s - loss: 0.0029 - acc: 0.9989 - val_loss: 0.0049 - val_acc: 0.9985
Epoch 39/40
13280/13280 [==============================] - 98s - loss: 0.0128 - acc: 0.9962 - val_loss: 0.0067 - val_acc: 0.9982
Epoch 40/40
13280/13280 [==============================] - 98s - loss: 0.0084 - acc: 0.9971 - val_loss: 0.0024 - val_acc: 0.9994





test log:

4146/4146 [==============================] - 8s      
acc: 99.06%